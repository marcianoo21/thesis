"""
examples.py

PrzykÅ‚ady uÅ¼ycia systemu RAG w rÃ³Å¼nych scenariuszach.
"""

import os
from dotenv import load_dotenv
from conversational_rag import create_rag_system, PLLuMLLM, ConversationalRAG


def example_1_basic_conversation():
    """PrzykÅ‚ad 1: Podstawowa konwersacja."""
    print("\n" + "="*60)
    print("PRZYKÅAD 1: Podstawowa konwersacja")
    print("="*60 + "\n")
    
    load_dotenv()
    rag, _ = create_rag_system()
    
    messages = [
        "CzeÅ›Ä‡!",
        "Szukam miejsca na romantycznÄ… kolacjÄ™",
        "CoÅ› z widokiem byÅ‚oby idealne",
    ]
    
    for msg in messages:
        print(f"ğŸ‘¤ Ty: {msg}")
        response = rag.generate_response(msg)
        print(f"ğŸ¤– Asystent: {response}\n")


def example_2_specific_search():
    """PrzykÅ‚ad 2: Konkretne wyszukiwanie."""
    print("\n" + "="*60)
    print("PRZYKÅAD 2: Konkretne wyszukiwanie")
    print("="*60 + "\n")
    
    load_dotenv()
    rag, _ = create_rag_system()
    
    query = "najlepsza pizzeria w Åodzi z dobrymi opiniami"
    print(f"ğŸ‘¤ Ty: {query}")
    response = rag.generate_response(query)
    print(f"ğŸ¤– Asystent: {response}\n")


def example_3_context_aware():
    """PrzykÅ‚ad 3: Kontekst w konwersacji."""
    print("\n" + "="*60)
    print("PRZYKÅAD 3: PamiÄ™tanie kontekstu")
    print("="*60 + "\n")
    
    load_dotenv()
    rag, _ = create_rag_system()
    
    messages = [
        "LubiÄ™ wÅ‚oskÄ… kuchniÄ™",
        "Ale nie jestem fanem pizzy",
        "Co moÅ¼esz mi poleciÄ‡?",
        "A gdzie jest to miejsce?",
    ]
    
    for msg in messages:
        print(f"ğŸ‘¤ Ty: {msg}")
        response = rag.generate_response(msg)
        print(f"ğŸ¤– Asystent: {response}\n")


def example_4_export_import():
    """PrzykÅ‚ad 4: Zapisywanie i wczytywanie konwersacji."""
    print("\n" + "="*60)
    print("PRZYKÅAD 4: Zapis i odczyt konwersacji")
    print("="*60 + "\n")
    
    load_dotenv()
    rag, _ = create_rag_system()
    
    # ProwadÅº krÃ³tkÄ… konwersacjÄ™
    rag.generate_response("Szukam kawiarni")
    rag.generate_response("Z dobrÄ… kawÄ…")
    
    # Zapisz
    filename = "test_conversation.json"
    rag.export_conversation(filename)
    print(f"âœ… Konwersacja zapisana do {filename}\n")
    
    # WyczyÅ›Ä‡ historiÄ™
    rag.clear_history()
    print(f"ğŸ“Š Historia po wyczyszczeniu: {len(rag.conversation_history)} wiadomoÅ›ci\n")
    
    # Wczytaj
    rag.load_conversation(filename)
    print(f"ğŸ“Š Historia po wczytaniu: {len(rag.conversation_history)} wiadomoÅ›ci\n")
    
    # Kontynuuj konwersacjÄ™
    response = rag.generate_response("A w centrum?")
    print(f"ğŸ¤– Kontynuacja: {response}\n")


def example_5_custom_prompt():
    """PrzykÅ‚ad 5: WÅ‚asny prompt systemowy."""
    print("\n" + "="*60)
    print("PRZYKÅAD 5: WÅ‚asny prompt systemowy")
    print("="*60 + "\n")
    
    load_dotenv()
    
    # WÅ‚asny prompt - bardziej zwiÄ™zÅ‚y styl
    custom_prompt = """JesteÅ› asystentem rekomendacji restauracji w Åodzi.

Zasady:
- Odpowiadaj zwiÄ™Åºle i konkretnie
- Podawaj maksymalnie TOP 3 miejsca
- Zawsze wspominaj oceny Google
- UÅ¼ywaj emoji ğŸ•ğŸ”ğŸœ dla typÃ³w kuchni

BÄ…dÅº profesjonalny ale przyjazny."""
    
    # StwÃ³rz system z wÅ‚asnym promptem
    _, search = create_rag_system()
    llm = PLLuMLLM()
    
    rag = ConversationalRAG(
        llm_client=llm,
        search_function=search,
        system_prompt=custom_prompt
    )
    
    query = "polecisz pizzeriÄ™?"
    print(f"ğŸ‘¤ Ty: {query}")
    response = rag.generate_response(query)
    print(f"ğŸ¤– Asystent: {response}\n")


def example_6_direct_llm():
    """PrzykÅ‚ad 6: BezpoÅ›rednie uÅ¼ycie LLM bez RAG."""
    print("\n" + "="*60)
    print("PRZYKÅAD 6: BezpoÅ›rednie uÅ¼ycie modelu PLLuM")
    print("="*60 + "\n")
    
    load_dotenv()
    
    llm = PLLuMLLM()
    
    messages = [
        {"role": "system", "content": "JesteÅ› pomocnym asystentem."},
        {"role": "user", "content": "Jakie sÄ… gÅ‚Ã³wne atrakcje Åodzi?"}
    ]
    
    response = llm.generate(
        messages,
        max_tokens=200,
        temperature=0.7
    )
    
    print(f"ğŸ¤– OdpowiedÅº: {response}\n")


def example_7_multi_turn_refinement():
    """PrzykÅ‚ad 7: Wieloetapowe doprecyzowanie."""
    print("\n" + "="*60)
    print("PRZYKÅAD 7: Doprecyzowanie wymagaÅ„")
    print("="*60 + "\n")
    
    load_dotenv()
    rag, _ = create_rag_system()
    
    messages = [
        "Szukam restauracji",
        "Azjatyckiej",
        "Ale bez sushi",
        "W budÅ¼ecie do 100zÅ‚ na osobÄ™",
        "I Å¼eby byÅ‚a w centrum",
    ]
    
    for msg in messages:
        print(f"ğŸ‘¤ Ty: {msg}")
        response = rag.generate_response(msg)
        print(f"ğŸ¤– Asystent: {response}\n")


def example_8_error_handling():
    """PrzykÅ‚ad 8: ObsÅ‚uga bÅ‚Ä™dÃ³w."""
    print("\n" + "="*60)
    print("PRZYKÅAD 8: ObsÅ‚uga bÅ‚Ä™dÃ³w")
    print("="*60 + "\n")
    
    # Test bez tokenu
    if "HF_TOKEN" in os.environ:
        backup_token = os.environ["HF_TOKEN"]
        del os.environ["HF_TOKEN"]
    else:
        backup_token = None
    
    try:
        llm = PLLuMLLM()
    except ValueError as e:
        print(f"âœ… Poprawnie zÅ‚apano bÅ‚Ä…d: {e}\n")
    
    # PrzywrÃ³Ä‡ token
    if backup_token:
        os.environ["HF_TOKEN"] = backup_token
    
    # Test z pustym zapytaniem
    load_dotenv()
    rag, _ = create_rag_system()
    
    empty_queries = ["", "   ", "asdfghjkl"]
    
    for query in empty_queries:
        print(f"ğŸ‘¤ Ty: '{query}'")
        try:
            response = rag.generate_response(query)
            print(f"ğŸ¤– Asystent: {response}\n")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d: {e}\n")


def main():
    """Uruchom wszystkie przykÅ‚ady."""
    examples = [
        ("Podstawowa konwersacja", example_1_basic_conversation),
        ("Konkretne wyszukiwanie", example_2_specific_search),
        ("PamiÄ™tanie kontekstu", example_3_context_aware),
        ("Zapis/odczyt konwersacji", example_4_export_import),
        ("WÅ‚asny prompt", example_5_custom_prompt),
        ("BezpoÅ›rednie uÅ¼ycie LLM", example_6_direct_llm),
        ("Doprecyzowanie wymagaÅ„", example_7_multi_turn_refinement),
        ("ObsÅ‚uga bÅ‚Ä™dÃ³w", example_8_error_handling),
    ]
    
    print("\nğŸ¯ PRZYKÅADY UÅ»YCIA SYSTEMU RAG\n")
    print("DostÄ™pne przykÅ‚ady:")
    for i, (name, _) in enumerate(examples, 1):
        print(f"  {i}. {name}")
    
    choice = input("\nWybierz przykÅ‚ad (1-8) lub 'all' aby uruchomiÄ‡ wszystkie: ").strip()
    
    if choice.lower() == "all":
        for name, func in examples:
            func()
            input("\nNaciÅ›nij Enter aby kontynuowaÄ‡...")
    else:
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(examples):
                examples[idx][1]()
            else:
                print("âŒ NieprawidÅ‚owy wybÃ³r!")
        except ValueError:
            print("âŒ NieprawidÅ‚owy wybÃ³r!")


if __name__ == "__main__":
    main()