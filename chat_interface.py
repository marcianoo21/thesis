"""
chat_interface.py

Interaktywny interfejs do konwersacyjnego systemu rekomendacji.
U≈ºywa PLLuM do naturalnej konwersacji po polsku.
"""

import os
import sys
import argparse
from dotenv import load_dotenv
from conversational_rag import create_rag_system, PLLuMLLM, ConversationalRAG
from config import get_config, list_profiles


def parse_arguments():
    """Parsuj argumenty wiersza polece≈Ñ."""
    parser = argparse.ArgumentParser(
        description="Konwersacyjny System Rekomendacji Restauracji - ≈Å√≥d≈∫"
    )
    
    parser.add_argument(
        "--profile",
        type=str,
        default="default",
        help="Profil konfiguracyjny (default, fast, detailed, friendly, professional, local, budget, foodie)"
    )
    
    parser.add_argument(
        "--list-profiles",
        action="store_true",
        help="Wy≈õwietl dostƒôpne profile i zako≈Ñcz"
    )
    
    parser.add_argument(
        "--embedding-file",
        type=str,
        default="output_files/lodz_restaurants_cafes_embeddings_mean.jsonl",
        help="≈öcie≈ºka do pliku z embeddingami"
    )
    
    return parser.parse_args()


def print_welcome(profile_name: str):
    """Wy≈õwietla powitalny banner."""
    print("\n" + "=" * 70)
    print("KONWERSACYJNY SYSTEM REKOMENDACJI RESTAURACJI ‚Äì ≈Å√ìD≈π")
    print("=" * 70)
    print(f"\nProfil: {profile_name.upper()}")
    print("Powered by PLLuM-12B + FAISS + RoBERTa embeddings")
    print()


def print_instructions():
    """Wy≈õwietla instrukcje u≈ºytkowania."""
    print("Komendy specjalne:")
    print("   ‚Ä¢ 'exit', 'quit', 'q' - zako≈Ñcz konwersacjƒô")
    print("   ‚Ä¢ 'clear', 'reset' - wyczy≈õƒá historiƒô konwersacji")
    print("   ‚Ä¢ 'save' - zapisz konwersacjƒô do pliku")
    print("   ‚Ä¢ 'profile' - poka≈º aktualny profil")
    print()
    print("-" * 70)
    print()


def main():
    """G≈Ç√≥wna pƒôtla czatu."""
    # Parsuj argumenty
    args = parse_arguments()
    
    # Je≈õli --list-profiles, wy≈õwietl i zako≈Ñcz
    if args.list_profiles:
        list_profiles()
        return
    
    # Za≈Çaduj zmienne ≈õrodowiskowe
    load_dotenv()
    
    # Sprawd≈∫ czy jest token HF
    if not os.getenv("HF_TOKEN"):
        print("B≈ÅƒÑD: Brak HF_TOKEN w zmiennych ≈õrodowiskowych!")
        print("   Ustaw token: export HF_TOKEN='tw√≥j_token'")
        print("   Lub dodaj do pliku .env: HF_TOKEN=tw√≥j_token")
        return
    
    # Za≈Çaduj konfiguracjƒô
    config = get_config(args.profile)
    
    print_welcome(args.profile)
    
    try:
        # Inicjalizuj system RAG
        print("Inicjalizacja systemu...")
        print(f"   Profil: {args.profile}")
        print(f"   Top-K: {config.top_k}")
        print(f"   Max tokens: {config.max_tokens}")
        print(f"   Temperature: {config.temperature}")
        print()
        
        # Za≈Çaduj wyszukiwarkƒô
        import numpy as np
        import faiss
        from sentence_transformers import SentenceTransformer
        import json
        
        model = SentenceTransformer(config.embedding_model)
        query_prefix = "zapytanie: "
        
        records = []
        embeddings = []
        
        with open(config.embedding_file, "r", encoding="utf-8") as f:
            for line in f:
                rec = json.loads(line)
                records.append(rec)
                embeddings.append(rec["embedding"])
        
        embeddings = np.array(embeddings).astype("float32")
        faiss.normalize_L2(embeddings)
        
        index = faiss.IndexFlatIP(embeddings.shape[1])
        index.add(embeddings)
        
        def search(query, k=None):
            if k is None:
                k = config.top_k
            full_query = query_prefix + query
            q_emb = model.encode(full_query, normalize_embeddings=True)
            q_emb = q_emb.astype("float32").reshape(1, -1)
            
            scores, idxs = index.search(q_emb, k)
            
            results = []
            for score, idx in zip(scores[0], idxs[0]):
                rec = records[idx]
                results.append({
                    "score": float(score),
                    "name": rec.get("name"),
                    "type": rec.get("type"),
                    "address": rec.get("Adres", "brak"),
                    "coords": rec.get("Wsp√≥≈Çrzƒôdne"),
                    "google_rating": rec.get("google_rating"),
                    "google_reviews_total": rec.get("google_reviews_total"),
                })
            
            results.sort(
                key=lambda x: (
                    -(x["google_rating"] or 0),
                    -(x["google_reviews_total"] or 0)
                )
            )
            
            return results
        
        # Stw√≥rz system RAG
        llm = PLLuMLLM()
        rag = ConversationalRAG(
            llm_client=llm,
            search_function=search,
            max_history=config.max_history,
            system_prompt=config.system_prompt
        )
        
        print(f"Indeks wczytany! Liczba restauracji: {index.ntotal}\n")
        
        print("Witaj! Jestem Twoim asystentem do rekomendacji restauracji.")
        print("Mogƒô Ci pom√≥c w wyborze miejsca do jedzenia w ≈Åodzi.\n")
        
        print_instructions()
        
        # G≈Ç√≥wna pƒôtla konwersacji
        while True:
            try:
                # Pobierz wiadomo≈õƒá od u≈ºytkownika
                user_input = input("Ty: ").strip()
                
                if not user_input:
                    continue
                
                # Obs≈Çuga komend specjalnych
                if user_input.lower() in ["exit", "quit", "q"]:
                    print("\nDziƒôkujƒô za rozmowƒô! Do widzenia! üëã\n")
                    
                    # Zapytaj czy zapisaƒá konwersacjƒô
                    save = input("Czy zapisaƒá konwersacjƒô? (t/n): ").strip().lower()
                    if save in ["t", "y", "tak", "yes"]:
                        filename = f"conversation_{args.profile}_{len(rag.conversation_history)//2}_messages.json"
                        rag.export_conversation(filename)
                    
                    break
                
                elif user_input.lower() in ["clear", "reset", "wyczy≈õƒá"]:
                    rag.clear_history()
                    print("Historia konwersacji wyczyszczona!\n")
                    continue
                
                elif user_input.lower() in ["save", "zapisz"]:
                    filename = input("Nazwa pliku (Enter = domy≈õlna): ").strip()
                    if not filename:
                        filename = f"conversation_{args.profile}_{len(rag.conversation_history)//2}_messages.json"
                    rag.export_conversation(filename)
                    print()
                    continue
                
                elif user_input.lower() in ["profile", "profil"]:
                    print(f"\nAktualny profil: {args.profile.upper()}")
                    print(f"   Top-K: {config.top_k}")
                    print(f"   Max history: {config.max_history}")
                    print(f"   Max tokens: {config.max_tokens}")
                    print(f"   Temperature: {config.temperature}")
                    print()
                    continue
                
                # Wygeneruj odpowied≈∫
                print("\nAsystent: ", end="", flush=True)
                
                # U≈ºyj konfiguracji dla generowania
                response = rag.llm.generate(
                    rag._prepare_messages(user_input),
                    max_tokens=config.max_tokens,
                    temperature=config.temperature
                )
                
                # Zaktualizuj historiƒô
                rag.conversation_history.append({"role": "user", "content": user_input})
                rag.conversation_history.append({"role": "assistant", "content": response})
                
                print(response)
                print()
                
            except KeyboardInterrupt:
                print("\n\nPrzerwano przez u≈ºytkownika. Do widzenia!\n")
                break
                
            except Exception as e:
                print(f"\nB≈ÇƒÖd: {e}\n")
                import traceback
                traceback.print_exc()
    
    except Exception as e:
        print(f"\nB≈ÇƒÖd inicjalizacji: {e}\n")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()